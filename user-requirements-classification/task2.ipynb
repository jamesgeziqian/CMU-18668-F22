{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db54b33-ac51-4960-9f09-10d8551b2a6c",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "654a2823-2ba6-4dfb-a9d5-2bb5275028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe29e0a5-21d4-480e-bc72-ba5c1fe6e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_label = 'stopwords_removal_nltk'\n",
    "label_name = 'label'\n",
    "senti_label = 'sentiScore'\n",
    "features = [text_label, senti_label, label_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6724f339-1bcd-477b-a71c-d09a627aaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    :param file_path: path to the json file\n",
    "\n",
    "    :return: an array in which each entry is tuple [review, classification label]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path) as json_file:\n",
    "        raw_data = json.load(json_file)\n",
    "    return convert_data(raw_data)\n",
    "\n",
    "\n",
    "def convert_data(raw_data):\n",
    "    extracted = [[elem[feat] for feat in features] for elem in raw_data]\n",
    "    return pd.DataFrame(extracted, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4505d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bug = load_file('Bug_tt.json')\n",
    "data_feat = load_file('Feature_tt.json')\n",
    "data_rating = load_file('Rating_tt.json')\n",
    "data_ux = load_file('UserExperience_tt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af52ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label(data: pd.DataFrame, label_name, inplace=False):\n",
    "    new_label = np.where(data[label_name] == label_name, 1, 0)\n",
    "    new_data = data if inplace else data.copy()\n",
    "    new_data[label_name] = new_label\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9ce2b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>sentiScore</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>still need check each, think need improve tech...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app helpful!!!! truly amazing!!!! paid bills</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awesome!!!</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love app takes less ten seconds let know batte...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's app pretty much everything making list of...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>crashes lenovo tablet app keeps crashing loses...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>terrible took forever download</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>norefund wtf seems like nice game working sgs2...</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>need speed wanted would good game would load i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>already paid paid game want money whole experi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                stopwords_removal_nltk  sentiScore  label\n",
       "0    still need check each, think need improve tech...           2      1\n",
       "1         app helpful!!!! truly amazing!!!! paid bills           4      1\n",
       "2                                           awesome!!!           4      1\n",
       "3    love app takes less ten seconds let know batte...           3      1\n",
       "4    it's app pretty much everything making list of...           3      1\n",
       "..                                                 ...         ...    ...\n",
       "735  crashes lenovo tablet app keeps crashing loses...          -2      0\n",
       "736                     terrible took forever download          -4      0\n",
       "737  norefund wtf seems like nice game working sgs2...          -3      0\n",
       "738  need speed wanted would good game would load i...           2      0\n",
       "739  already paid paid game want money whole experi...          -1      0\n",
       "\n",
       "[740 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_label(data_bug, 'Bug', inplace=True)\n",
    "transform_label(data_feat, 'Feature', inplace=True)\n",
    "transform_label(data_rating, 'Rating', inplace=True)\n",
    "transform_label(data_ux, 'UserExperience', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65b0ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bug, X_test_bug, y_train_bug, y_test_bug = train_test_split(\n",
    "    data_bug[[text_label, senti_label]], data_bug[label_name], test_size=.15, random_state=42)\n",
    "X_train_feat, X_test_feat, y_train_feat, y_test_feat = train_test_split(\n",
    "    data_feat[[text_label, senti_label]], data_feat[label_name], test_size=.15, random_state=42)\n",
    "X_train_rating, X_test_rating, y_train_rating, y_test_rating = train_test_split(\n",
    "    data_rating[[text_label, senti_label]], data_rating[label_name], test_size=.15, random_state=42)\n",
    "X_train_ux, X_test_ux, y_train_ux, y_test_ux = train_test_split(\n",
    "    data_ux[[text_label, senti_label]], data_ux[label_name], test_size=.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823e5ca",
   "metadata": {},
   "source": [
    "Tfidf Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9eee850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "NGRAM_RANGE = (1, 2)\n",
    "MIN_DF = .01  # ignore terms that appear in less than 1% of the documents\n",
    "MAX_DF = .8  # ignore terms that appear in more than 80% of the documents\n",
    "MAX_FEATURES = 300\n",
    "\n",
    "def vectorized_text(train, test):\n",
    "    tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                            ngram_range=NGRAM_RANGE,\n",
    "                            stop_words=None,\n",
    "                            lowercase=False,\n",
    "                            max_df=MAX_DF,\n",
    "                            min_df=MIN_DF,\n",
    "                            max_features=MAX_FEATURES,\n",
    "                            norm='l2',\n",
    "                            sublinear_tf=True)\n",
    "    features_train = tfidf.fit_transform(train).toarray()\n",
    "    features_test = tfidf.transform(test).toarray()\n",
    "    return features_train, features_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7aca9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec_bug, X_test_vec_bug = vectorized_text(X_train_bug[text_label], X_test_bug[text_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ffcf6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bug_vec_senti = np.append(\n",
    "    X_train_vec_bug, X_train_bug[[senti_label]].to_numpy(), axis=1)\n",
    "X_test_bug_vec_senti = np.append(X_test_vec_bug, X_test_bug[[senti_label]].to_numpy(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e54a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43021057, 0.56978943],\n",
       "       [0.41888333, 0.58111667],\n",
       "       [0.23149543, 0.76850457],\n",
       "       [0.33602197, 0.66397803],\n",
       "       [0.816044  , 0.183956  ],\n",
       "       [0.94183234, 0.05816766],\n",
       "       [0.33185109, 0.66814891],\n",
       "       [0.65935388, 0.34064612],\n",
       "       [0.28939056, 0.71060944],\n",
       "       [0.22292645, 0.77707355],\n",
       "       [0.24464754, 0.75535246],\n",
       "       [0.97980484, 0.02019516],\n",
       "       [0.66367196, 0.33632804],\n",
       "       [0.90534764, 0.09465236],\n",
       "       [0.91987781, 0.08012219],\n",
       "       [0.82447043, 0.17552957],\n",
       "       [0.60620484, 0.39379516],\n",
       "       [0.14492329, 0.85507671],\n",
       "       [0.17488222, 0.82511778],\n",
       "       [0.20226863, 0.79773137],\n",
       "       [0.93543808, 0.06456192],\n",
       "       [0.2572643 , 0.7427357 ],\n",
       "       [0.38319337, 0.61680663],\n",
       "       [0.31948872, 0.68051128],\n",
       "       [0.86817738, 0.13182262],\n",
       "       [0.83570107, 0.16429893],\n",
       "       [0.22692273, 0.77307727],\n",
       "       [0.91646753, 0.08353247],\n",
       "       [0.63491253, 0.36508747],\n",
       "       [0.90207814, 0.09792186],\n",
       "       [0.21331917, 0.78668083],\n",
       "       [0.74553385, 0.25446615],\n",
       "       [0.44858033, 0.55141967],\n",
       "       [0.41227993, 0.58772007],\n",
       "       [0.22162799, 0.77837201],\n",
       "       [0.47987184, 0.52012816],\n",
       "       [0.84739811, 0.15260189],\n",
       "       [0.22273022, 0.77726978],\n",
       "       [0.24215504, 0.75784496],\n",
       "       [0.97980484, 0.02019516],\n",
       "       [0.23076023, 0.76923977],\n",
       "       [0.2469463 , 0.7530537 ],\n",
       "       [0.70888484, 0.29111516],\n",
       "       [0.94183234, 0.05816766],\n",
       "       [0.54390931, 0.45609069],\n",
       "       [0.91984888, 0.08015112],\n",
       "       [0.20660693, 0.79339307],\n",
       "       [0.17950462, 0.82049538],\n",
       "       [0.19046447, 0.80953553],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.11887754, 0.88112246],\n",
       "       [0.4603067 , 0.5396933 ],\n",
       "       [0.64538965, 0.35461035],\n",
       "       [0.08638959, 0.91361041],\n",
       "       [0.97980484, 0.02019516],\n",
       "       [0.64928148, 0.35071852],\n",
       "       [0.39379921, 0.60620079],\n",
       "       [0.10228839, 0.89771161],\n",
       "       [0.48015797, 0.51984203],\n",
       "       [0.38243446, 0.61756554],\n",
       "       [0.15688209, 0.84311791],\n",
       "       [0.90793691, 0.09206309],\n",
       "       [0.93543808, 0.06456192],\n",
       "       [0.97980484, 0.02019516],\n",
       "       [0.94759281, 0.05240719],\n",
       "       [0.93543808, 0.06456192],\n",
       "       [0.55834799, 0.44165201],\n",
       "       [0.35126895, 0.64873105],\n",
       "       [0.83396061, 0.16603939],\n",
       "       [0.59026057, 0.40973943],\n",
       "       [0.34901499, 0.65098501],\n",
       "       [0.57381978, 0.42618022],\n",
       "       [0.1693518 , 0.8306482 ],\n",
       "       [0.96838149, 0.03161851],\n",
       "       [0.28558672, 0.71441328],\n",
       "       [0.17377986, 0.82622014],\n",
       "       [0.31796138, 0.68203862],\n",
       "       [0.68041151, 0.31958849],\n",
       "       [0.34563703, 0.65436297],\n",
       "       [0.63713733, 0.36286267],\n",
       "       [0.97980484, 0.02019516],\n",
       "       [0.10152543, 0.89847457],\n",
       "       [0.0721453 , 0.9278547 ],\n",
       "       [0.13424799, 0.86575201],\n",
       "       [0.93959126, 0.06040874],\n",
       "       [0.46566928, 0.53433072],\n",
       "       [0.24194828, 0.75805172],\n",
       "       [0.32412378, 0.67587622],\n",
       "       [0.21643826, 0.78356174],\n",
       "       [0.34501869, 0.65498131],\n",
       "       [0.31845603, 0.68154397],\n",
       "       [0.37566078, 0.62433922],\n",
       "       [0.93959126, 0.06040874],\n",
       "       [0.14161343, 0.85838657],\n",
       "       [0.662067  , 0.337933  ],\n",
       "       [0.87235621, 0.12764379],\n",
       "       [0.17494149, 0.82505851],\n",
       "       [0.16509331, 0.83490669],\n",
       "       [0.71841643, 0.28158357],\n",
       "       [0.09436886, 0.90563114],\n",
       "       [0.23626447, 0.76373553],\n",
       "       [0.32938047, 0.67061953],\n",
       "       [0.94410637, 0.05589363],\n",
       "       [0.20726364, 0.79273636],\n",
       "       [0.91983892, 0.08016108],\n",
       "       [0.95933548, 0.04066452],\n",
       "       [0.79227449, 0.20772551],\n",
       "       [0.22969636, 0.77030364],\n",
       "       [0.36753637, 0.63246363],\n",
       "       [0.39058211, 0.60941789],\n",
       "       [0.20541446, 0.79458554]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', probability=True))\n",
    "clf.fit(X_train_bug_vec_senti, y_train_bug)\n",
    "clf.predict_proba(X_test_bug_vec_senti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b6ac3480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OVRClassifier:\n",
    "    def __init__(self) -> None:\n",
    "        self.bug_scaler = StandardScaler()\n",
    "        self.bug_clf = SVC(gamma='auto', probability=True)\n",
    "        self.bug_vectorizer = self._make_tfidf()\n",
    "        self.feat_scaler = StandardScaler()\n",
    "        self.feat_clf = SVC(gamma='auto', probability=True)\n",
    "        self.feat_vectorizer = self._make_tfidf()\n",
    "        self.rating_scaler = StandardScaler()\n",
    "        self.rating_clf = SVC(gamma='auto', probability=True)\n",
    "        self.rating_vectorizer = self._make_tfidf()\n",
    "        self.ux_scaler = StandardScaler()\n",
    "        self.ux_clf = SVC(gamma='auto', probability=True)\n",
    "        self.ux_vectorizer = self._make_tfidf()\n",
    "\n",
    "    def _make_tfidf(self, ngram_range=NGRAM_RANGE, max_df=MAX_DF, min_df=MIN_DF, max_features=MAX_FEATURES):\n",
    "        return TfidfVectorizer(encoding='utf-8',\n",
    "                               ngram_range=ngram_range,\n",
    "                               stop_words=None,\n",
    "                               lowercase=False,\n",
    "                               max_df=max_df,\n",
    "                               min_df=min_df,\n",
    "                               max_features=max_features,\n",
    "                               norm='l2',\n",
    "                               sublinear_tf=True)\n",
    "\n",
    "    def _fit(self, X, y, vectorizer, scaler, clf):\n",
    "        X_vec = vectorizer.fit_transform(X[text_label]).toarray()\n",
    "        X_vec_senti = np.append(\n",
    "            X_vec, X[[senti_label]].to_numpy(), axis=1)\n",
    "        X_normalized = scaler.fit_transform(X_vec_senti)\n",
    "        clf.fit(X_normalized, y)\n",
    "        print(f'Training accuracy: {clf.score(X_normalized, y)}')\n",
    "\n",
    "    def _fit_bug(self, X, y):\n",
    "        self._fit(X, y, self.bug_vectorizer, self.bug_scaler, self.bug_clf)\n",
    "\n",
    "    def _fit_feat(self, X, y):\n",
    "        self._fit(X, y, self.feat_vectorizer,\n",
    "                  self.feat_scaler, self.feat_clf)\n",
    "\n",
    "    def _fit_rating(self, X, y):\n",
    "        self._fit(X, y, self.rating_vectorizer,\n",
    "                  self.rating_scaler, self.rating_clf)\n",
    "\n",
    "    def _fit_ux(self, X, y):\n",
    "        self._fit(X, y, self.ux_vectorizer,\n",
    "                  self.ux_scaler, self.ux_clf)\n",
    "\n",
    "    def _predict_proba(self, X, vectorizer, scaler, clf):\n",
    "        X_vec = vectorizer.transform(X[text_label]).toarray()\n",
    "        X_vec_senti = np.append(X_vec, X[[senti_label]].to_numpy(), axis=1)\n",
    "        X_normalized = scaler.transform(X_vec_senti)\n",
    "        return clf.predict_proba(X_normalized)\n",
    "\n",
    "    def _predict(self, X, vectorizer, scaler, clf):\n",
    "        predicted_proba = self._predict_proba(X, vectorizer, scaler, clf)\n",
    "        return np.argmax(predicted_proba, axis=1)\n",
    "\n",
    "    def _predict_bug(self, X):\n",
    "        return self._predict(X, self.bug_vectorizer, self.bug_scaler, self.bug_clf)\n",
    "\n",
    "    def fit(self, X_bug, y_bug, X_feat, y_feat, X_rating, y_rating, X_ux, y_ux):\n",
    "        self._fit_bug(X_bug, y_bug)\n",
    "        self._fit_feat(X_feat, y_feat)\n",
    "        self._fit_rating(X_rating, y_rating)\n",
    "        self._fit_ux(X_ux, y_ux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "737246a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9697933227344993\n",
      "Training accuracy: 0.9770554493307839\n",
      "Training accuracy: 0.9745627980922098\n",
      "Training accuracy: 0.9475357710651828\n",
      "Testing\n",
      "Accuracy: 0.7387387387387387\n",
      "F1 score: 0.7563025210084034\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.8035714285714286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ova_clf = OVRClassifier()\n",
    "ova_clf.fit(X_train_bug, y_train_bug, X_train_feat, y_train_feat,\n",
    "            X_train_rating, y_train_rating, X_train_ux, y_train_ux)\n",
    "predicted_bug_test = ova_clf._predict_bug(X_test_bug)\n",
    "print(f'''Testing\n",
    "Accuracy: {accuracy_score(y_test_bug, predicted_bug_test)}\n",
    "F1 score: {f1_score(y_test_bug, predicted_bug_test)}\n",
    "Precision: {precision_score(y_test_bug, predicted_bug_test)}\n",
    "Recall: {recall_score(y_test_bug, predicted_bug_test)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0d2e7dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>sentiScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>love app, cant access recipes saved online sav...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>probably great app 4 up ive used several 2 yea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>brilliant app crashes ipad iphone</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>hotel reviews, especially poor hotels, fake li...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>cant even download purchased game wont even do...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>thanks thought &amp; effort went creating app hand...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>bad</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>somehow lost contacts app got everything back</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>its awesome however recently lapse receive mes...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>downloaded latest update app disappeared, app ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                stopwords_removal_nltk  sentiScore\n",
       "120  love app, cant access recipes saved online sav...           3\n",
       "416  probably great app 4 up ive used several 2 yea...           3\n",
       "334                  brilliant app crashes ipad iphone           2\n",
       "350  hotel reviews, especially poor hotels, fake li...          -2\n",
       "412  cant even download purchased game wont even do...          -1\n",
       "..                                                 ...         ...\n",
       "582  thanks thought & effort went creating app hand...           3\n",
       "641                                                bad          -3\n",
       "548      somehow lost contacts app got everything back          -1\n",
       "148  its awesome however recently lapse receive mes...           3\n",
       "324  downloaded latest update app disappeared, app ...          -1\n",
       "\n",
       "[111 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5af6154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120    1\n",
       "416    0\n",
       "334    1\n",
       "350    1\n",
       "412    0\n",
       "      ..\n",
       "582    0\n",
       "641    0\n",
       "548    0\n",
       "148    1\n",
       "324    1\n",
       "Name: label, Length: 111, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dsse-requirement-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ced77ce54103669f042cadd2c18ce665f84a2ca19bb667c3bb1aa7be7a300795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
